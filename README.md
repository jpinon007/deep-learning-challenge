# deep-learning-challenge

# Background: The nonprofit foundation Alphabet Soup wants a tool that can help it select the applicants for funding with the best chance of success. With my knowledge of machine learning and neural networks, I have been tasked to use the features in the provided dataset to create a binary classifier that can predict whether applucants will be successful if funded by Alphabet Soup. From Alphabet Soup’s business team, I have received a CSV containing more than 34,000 organizations that have received funding from Alphabet Soup over the years. Within this dataset are a number of columns that capture metadata about each organization, such as: EIN and NAME—Identification columns, APPLICATION_TYPE—Alphabet Soup application type, AFFILIATION—Affiliated sector of industry,CLASSIFICATION—Government organization classification, USE_CASE—Use case for funding, ORGANIZATION—Organization type, STATUS—Active status, INCOME_AMT—Income classification, SPECIAL_CONSIDERATIONS—Special considerations for application, ASK_AMT—Funding amount requested, and IS_SUCCESSFUL—Was the money used effectively.

# Solution: To complete this assignment, I used this repo for refernce to review my code https://github.com/JLeigh101/deep-learning-challenge . 

# Part 1 preprocess data: I started by reading the charity_data.csv file to a Pandas DataFrame and identifying the variables, targets, and features for my model. I dropped the EIN and NAME columns. I determined the number of unique values for each column. Next, for the columns that have more than 10 unique values, I determined the number of data points for each unique value. I used the number of data points for each unique value to pick a cutoff point to comine the "rare" categorical variables together in a new value, Other, and then check if the replacement was successful. I then used pd.get_dummies() to enocde categorical variables. I split the preprocessed data into a features datasets by creating a StandardScaler instance, fitting it to the training data, then using the transform function. 

# Part 2 complie, train, and evaluate the model: Using my knowledge of TensorFlow, I was tasked to design a neural network to create a binary classification model that can predict if an Alphabet Soup-funded organization will be successful based on the features in the dataset. I continued to use the preprocessed file, I created a neural network model by assigning the number of input features and nodes for each layer using TensorFlow and Keras. Next, I created a first hidden layer and chose an appropriate activation function. I added a second hidden layer and chose an appropriate activate function, and created an output layer with an activation function. I checked the structure of the model and complied and trained the model. Next, I created a callback that would save the model's weights every five epochs, and evaluated the model using the test data to determine the loss and accuracy. Finally, i saved and exported my results to an HDF5 files names AlphabetSoupCharity.h5.